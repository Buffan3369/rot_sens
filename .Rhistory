gol <- read.csv("C:/Users/lucas/OneDrive/Bureau/Internship_2022/project/extracted_paleocoordinates/Golonka.csv")
saveRDS(gol, "./data/Golonka_extracted_paleocoordinates.RDS")
View(gol)
gol <- gol[, -c(1)]
saveRDS(gol, "./data/Golonka_extracted_paleocoordinates.RDS")
loG <- readRDS("./data/Golonka_extracted_paleocoordinates.RDS")
View(loG)
gol <- read.csv("C:/Users/lucas/OneDrive/Bureau/Internship_2022/project/extracted_paleocoordinates/Matthews.csv")[, -c(1)]
saveRDS(gol, "./data/Matthews_extracted_paleocoordinates.RDS")
gol <- read.csv("C:/Users/lucas/OneDrive/Bureau/Internship_2022/project/extracted_paleocoordinates/Seton.csv")[, -c(1)]
saveRDS(gol, "./data/Seton_extracted_paleocoordinates.RDS")
gol <- read.csv("C:/Users/lucas/OneDrive/Bureau/Internship_2022/project/extracted_paleocoordinates/Scotese2.csv")[, -c(1)]
saveRDS(gol, "./data/Scotese2_extracted_paleocoordinates.RDS")
## Loading libraries ---------------------------------------------------------------------------------------------------
library(raster)
## Working directory ---------------------------------------------------------------------------------------------------
setwd("./data/continental_polygons/")
#we look for potential remaining NAs in the other models after removing all cells not covered by Golonka
## Working directory ----------------------------------------------------------------------------------------
setwd('data/extracted_paleocoordinates')
#we look for potential remaining NAs in the other models after removing all cells not covered by Golonka
## Working directory ----------------------------------------------------------------------------------------
setwd('./data/extracted_paleocoordinates')
setwd()
#we look for potential remaining NAs in the other models after removing all cells not covered by Golonka
## Working directory ----------------------------------------------------------------------------------------
setwd('Home/GitHub/data/extracted_paleocoordinates')
setwd("~")
getwd()
#we look for potential remaining NAs in the other models after removing all cells not covered by Golonka
## Working directory ----------------------------------------------------------------------------------------
setwd('~/data/extracted_paleocoordinates')
#we look for potential remaining NAs in the other models after removing all cells not covered by Golonka
## Working directory ----------------------------------------------------------------------------------------
setwd("~")
setwd('./data/extracted_paleocoordinates')
getwd()
#we look for potential remaining NAs in the other models after removing all cells not covered by Golonka
## Working directory ----------------------------------------------------------------------------------------
setwd('~/GitHub/rot_sens/data/extracted_paleocoordinates')
getwd()
## Loading libraries ---------------------------------------------------------------------------------------------------
library(raster)
## Working directory ---------------------------------------------------------------------------------------------------
setwd("~/GitHub/rot_sens/data/data/continental_polygons/")
getwd()
getwd()
getwd()
## Loading libraries ---------------------------------------------------------------------------------------------------
library(raster)
r <- raster(res = 1) #start with a 1x1 raster
pos <- xyFromCell(object = r, cell = 1:ncell(r))  #extract coordinates as a df
xy <- data.frame(pos)
xy$Beginning <- 500 #500Ma ago, beginning of rotation
xy$End <- 0
############# IMPORT MODELS' POLYGONS AS SHAPEFILES AND PROCEED TO THE GEOREFERENCING ################
source("./R/georeferencing_and_NA_pos.R")
scot <- readRDS(file = "./data/extracted_paleocoordinates/Scotese2_extracted_paleocoordinates.RDS")
View(scot)
View(scot)
############# IMPORT MODELS' POLYGONS AS SHAPEFILES AND PROCEED TO THE GEOREFERENCING ################
source("./R/georeferencing_and_NA_pos.R")
###################################### COMPARISON ################################################
#we scale all models on the same grid-cells (maximise the get_na_pos() function for all models of "models")
#Loop to return the indexes of the NA of the models having the smaller coverage (hence the maximal number of cells with no attribute)
source("./R/cells_to_drop.R")
###################################### COMPARISON ################################################
#we scale all models on the same grid-cells (maximise the get_na_pos() function for all models of "models")
#Loop to return the indexes of the NA of the models having the smaller coverage (hence the maximal number of cells with no attribute)
source("./R/cells_to_drop.R")
########## LATITUDE STANDARD DEVIATION ###########
source("./R/lat_sd.R")
SD <- assess_sd(mdl_list = models) #model list created in the "cells_to_drop.R" file
gc()
SD_df <- data.frame(SD)
#we get the initial coordinates of the spatial data points (will be used after as subtracting two dfs makes them = 0, which is annoying for the rest of the work)
coords_ref <- read.csv('./data/extracted_paleocoordinates/Scotese2.RDS')[,1:2]
#we get the initial coordinates of the spatial data points (will be used after as subtracting two dfs makes them = 0, which is annoying for the rest of the work)
coords_ref <- readRDS('./data/extracted_paleocoordinates/Scotese2.RDS')[,1:2]
SD_df[, 1:2] <- coords_ref
View(SD_df)
df <- data.frame(A = c(1,2,3,4),
B = c(5,6,3,8),
C = c(4,5,3,6))
df*2
saveRDS(df, "./data/test1.RDS")
saveRDS(df*2, "./data/test2.RDS")
saveRDS(df/3, "./data/test3.RDS")
saveRDS(df*4, "./data/test4.RDS")
df1 <- readRDS("./data/test1.RDS")
df2 <- readRDS("./data/test2.RDS")
df3 <- readRDS("./data/test3.RDS")
df4 <- readRDS('./data/test4.RDS')
comb_array <- abind(df1, df2, df3, df4, along = 3) #we combine the 2-dimensional arrays in one 3D array (along = 3) for which we'll assess sd
SD <- apply(comb_array,
MARGIN = c(1,2), #on the 2 dimensions of the resulting array
FUN = sd) #we apply the sd function
SD
SD_df <- data.frame(SD)
SD_df
MaxTime <- c("Scotese2" = 540,
"Matthews" = 410,
"Golonka" = 540, #rounded to 540 (instead of 544) for Golonka
"Seton" = 200)  #the maximum time we want to reach, we basically go as far as the model goes
assess_sd <- function(mdl_list){
df1 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[1]], '.RDS'))
print(nrow(df1))
df2 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[2]], '.RDS'))
print(nrow(df2))
df3 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[3]], '.RDS'))
print(nrow(df3))
df4 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[4]], '.RDS'))
print(nrow(df4))
chosen_time <- min(MaxTime)
#spatial scaling
df1[MAX, ] = NA  #MAX returned by the "cells_to_drop.R" script
df2[MAX, ] = NA
df3[MAX, ] = NA
df4[MAX, ] = NA
#temporal scaling
df1 <- df1[, seq(from = 1, to = 2*(chosen_time/10 + 1), by = 1)]
df2 <- df2[, seq(from = 1, to = 2*(chosen_time/10 + 1), by = 1)]
df3 <- df3[, seq(from = 1, to = 2*(chosen_time/10 + 1), by = 1)]
df3 <- df3[, seq(from = 1, to = 2*(chosen_time/10 + 1), by = 1)]
comb_array <- abind(df1, df2, df3, df4, along = 3) #we combine the 2-dimensional arrays in one 3D array (along = 3) for which we'll assess sd
SD <- apply(comb_array,
MARGIN = c(1,2), #on the 2 dimensions of the resulting array
FUN = sd) #we apply the sd function
return(SD)
}
SD <- assess_sd(models)
mdl_list <- models
df1 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[1]], '.RDS'))
print(nrow(df1))
df2 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[2]], '.RDS'))
print(nrow(df2))
df3 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[3]], '.RDS'))
print(nrow(df3))
df4 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[4]], '.RDS'))
print(nrow(df4))
chosen_time <- min(MaxTime)
print(chosen_time)
df1[MAX, ] = NA  #MAX returned by the "cells_to_drop.R" script
df2[MAX, ] = NA
length(MAX)
df1[1,1]
head(MAX)
df1 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[1]], '.RDS'))
print(nrow(df1))
df2 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[2]], '.RDS'))
print(nrow(df2))
df1[1,] <- NA
df1[c(1,2,3,4), ] <- NA
class(MAX)
class(c(1,2,3,4))
df1[as.numeric(MAX), ] <- NA
df1[MAX, ] = NA  #MAX returned by the "cells_to_drop.R" script
for(k in MAX){
df1[k, ] <- NA
}
df1 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[1]], '.RDS'))
for(k in MAX){
df1[k, ] <- NA
}
clas(df1)
class(df1)
df1[MAX[1:10], ] <- NA
df1[MAX[1:length(MAX)], ] <- NA
MAX %in% rownames(df1)
casse_couilles <- c()
for(k in MAX){
if(k %in% rownames(df1) == FALSE)
casse_couilles <- c(casse_couilles, k)
}
df1 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[1]], '.RDS'))
casse_couilles <- c()
for(k in MAX){
if(k %in% rownames(df1) == FALSE)
casse_couilles <- c(casse_couilles, k)
}
casse_couilles <- which(MAX %in% rownames(df1) == FALSE)
rownames(df1) <- seq(from = 1, to = nrow(df1), by = 1)
casse_couilles <- which(MAX %in% rownames(df1) == FALSE)
df1 <- readRDS(file = paste0("./data/extracted_paleocoordinates/", mdl_list[[1]], '.RDS'))
rownames(df1) == seq(from = 1, to = nrow(df1), by = 1)
df1[34652, ]
df1[34652, ] = NA
casse_couilles
MAX[34652]
i = 1
MAX <- get_na_pos(models[i]) # function in "georeferencing_and_NA_pos.R" script
while(i<4){
i = i+1
test <- get_na_pos(models[i])
if(length(test) > length(MAX)){
MAX <- test
print(models[i]) #GOLONKA IS THE MODEL WITH THE SMALLER NUMBER OF CELLS WITH VALUES
}
} #length(MAX) = 34651
to_add <- c() #list that will contain the indexes to add, ie remaining NAs in the Matthew and Scotese datasets after cleaning golonka's NAs position
for(mdl in c("Scotese2", "Matthews")){
georef <- readRDS(paste0("./data/georeferenced/", mdl,".RDS"))
to_add <- c(to_add, which(is.na(georef[-MAX, ]) == TRUE)) #we add the remaining NAs after cleaning up Golonka's ones
}
A = readRDS("./data/georeferenced/Scotese2.RDS")
td <- which(is.na(A[-MAX, ] == TRUE))
df1[as.numeric(MAX), ] <- NA
rownames(A) = seq(from = 1, to = nrow(A), by = 1)
td <- which(is.na(A[-MAX, ] == TRUE))
A = readRDS("./data/georeferenced/Scotese2.RDS")
rownames(A) = seq(from = 1, to = nrow(A), by = 1)
td1 <- which(is.na(A[-MAX, ] == TRUE))
A = readRDS("./data/georeferenced/Matthews.RDS")
td1 <- which(is.na(A[-MAX, ] == TRUE))
View(A)
1260/(28889+1260)
td1 <- which(is.na(A[-MAX, ] == FALSE))
A = readRDS("./data/georeferenced/Matthews.RDS")
rownames(A) = seq(from = 1, to = nrow(A), by = 1)
td1 <- which(is.na(A[-MAX, ] == FALSE))
td1 <- which(is.na(A[-MAX, ] == TRUE))
td1 <- which(is.na(A$georef[-MAX] == TRUE))
############# IMPORT MODELS' POLYGONS AS SHAPEFILES AND PROCEED TO THE GEOREFERENCING ################
source("./R/georeferencing_and_NA_pos.R")
###################################### COMPARISON ################################################
#we scale all models on the same grid-cells (maximise the get_na_pos() function for all models of "models")
#Loop to return the indexes of the NA of the models having the smaller coverage (hence the maximal number of cells with no attribute)
source("./R/cells_to_drop.R")
########## LATITUDE STANDARD DEVIATION ###########
source("./R/lat_sd.R")
SD <- assess_sd(mdl_list = models) #model list created in the "cells_to_drop.R" file
SD_df <- data.frame(SD)
#we get the initial coordinates of the spatial data points (will be used after as subtracting two dfs makes them = 0, which is annoying for the rest of the work)
coords_ref <- readRDS('./data/extracted_paleocoordinates/Scotese2.RDS')[,1:2]
SD_df[, 1:2] <- coords_ref
saveRDS(SD_df, "./data/standard_deviation_4mdls.RDS")
########## LATITUDE DEVIATION (between outputs 2 by 2) ############
source("./R/lat_dev_2_by_2.R")
i = 1 #while loop to run the functions comparing the outputs of each model 2 by 2 (avoiding to compare twice the same models and also not comparing a model with itself)
models_copy = models
thr = 0.5 #all values under 0.5 degrees will be considered as unsignificant change
while(i <= length(models)){
mdl1 <- models[[i]]
for(mdl2 in models_copy){
if(mdl1 != mdl2){
difference <- assess_diff(mdl1, mdl2, thr)
write.csv(difference,
file = paste0("./data/", mdl1, '_', mdl2, 'diff.csv'))
}
}
models_copy = models_copy[-1]  #we get rid of the new first element
i = i+1
}
i = 1 #while loop to run the functions comparing the outputs of each model 2 by 2 (avoiding to compare twice the same models and also not comparing a model with itself)
models_copy = models
thr = 0.5 #all values under 0.5 degrees will be considered as unsignificant change
while(i <= length(models)){
mdl1 <- models[[i]]
for(mdl2 in models_copy){
if(mdl1 != mdl2){
difference <- assess_diff(mdl1, mdl2, thr)
saveRDS(difference,
file = paste0("./data/", mdl1, '_', mdl2, 'diff.RDS'))
}
}
models_copy = models_copy[-1]  #we get rid of the new first element
i = i+1
}
store <- readRDS('./data/georeferenced/Scotese2.RDS')
View(store)
store <- readRDS('./data/georeferenced/Scotese2.RDS')[, c(1,2,8)
]
i = 1
while(i < length(without_seton)){
i = i+1
store[,i+2] <- readRDS(paste0('./data/georeferenced/', models[i], '.RDS'))$georef
}
without_seton <- models[-c(4)]
i = 1
while(i < length(without_seton)){
i = i+1
store[,i+2] <- readRDS(paste0('./data/georeferenced/', models[i], '.RDS'))$georef
}
colnames(store) <- c("lon_0", "lat_0", "Scotese2_ID", "Matthews_ID", "Golonka_ID")
store <- store[-MAX,]
68000-35911
store$ID_weight <- 0
for(id in 1:nrow(store)){
store$ID_weight[id] <- length(unique(as.numeric(store[id,3:6])))  #the length of the plateID row without duplicates
}
saveRDS(store, file = "data_pts_plate_IDs_according_to_the_four_models.RDS")
store <- readRDS("./data/data_pts_plate_IDs_according_to_the_four_models.RDS")
r <- rasterFromXYZ(store[,c(1,2,6)], crs = "+proj=longlat +datum=WGS84")
proj_moll <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0"  #mollweide
p <- projectRaster(r, crs = proj_moll)
library(rnaturalearth)
library(sf)
#set background map using rnaturalearth
#coastlines
worldline <- ne_coastline(scale = 50)
worldline_mol <- spTransform(x = worldline,
CRSobj = "+proj=moll +lon_0=0 +x_0=0 +y_0=0")
par(bg = 'white')
plot(p, col = c('grey', 'yellow', 'red'),  axes = FALSE, add = FALSE)
plot(worldline_mol,
add = TRUE)
for(id in 1:nrow(store)){
store$ID_weight[id] <- length(unique(as.numeric(store[id,3:5])))  #the length of the plateID row without duplicates
}
saveRDS(store, file = "./data/data_pts_plate_IDs_according_to_the_four_models.RDS")
store <- readRDS("./data/data_pts_plate_IDs_according_to_the_four_models.RDS")
r <- rasterFromXYZ(store[,c(1,2,6)], crs = "+proj=longlat +datum=WGS84")
proj_moll <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0"  #mollweide
p <- projectRaster(r, crs = proj_moll)
plot.new()
par(bg = 'white')
plot(p, col = c('grey', 'yellow', 'red'),  axes = FALSE, add = FALSE)
plot(worldline_mol,
add = TRUE)
## set the background map -------------------------------------------------------------
source("./R/background_map.R")
#Rasterizing
r <- rasterFromXYZ(store[,c(1,2,6)], crs = "+proj=longlat +datum=WGS84")
## Import model's polygons as shapefiles and proceed to the georeferencing ----------------------------
source("./R/georeferencing_and_NA_pos.R")
## COMPARISON ------------------------------------------------------------------------------------------
#we scale all models on the same grid-cells (maximise the get_na_pos() function for all models of "models")
#Loop to return the indexes of the NA of the models having the smaller coverage (hence the maximal number of cells with no attribute)
source("./R/cells_to_drop.R")
## Latitude standard deviation -------------------------------------------------------------------------
source("./R/lat_sd.R")
## Plate ID assignment discrepancies --------------------------------------------------------------------
source("./R/ID_weight.R") #generates the dataframe containing the ID_weights for all our cells
## Latitude deviation (between outputs 2 by 2) ----------------------------------------------------------
source("./R/lat_dev_2_by_2.R")
## set the background map -------------------------------------------------------------
source("./R/background_map.R")
## Plot and save latitude standard deviation time series ------------------------------
source("./R/plot_lat_sd.R")
## Plot and save latitude deviation 2 by 2 for all the models time series -------------
source("./R/plot_lat_deviation.R")
models <- c("Scotese2",  #PALEOMAP latest version
"Matthews",
"Golonka",
"Seton")
#set the color palette
pal <- c('#ffeda0','#fed976','#feb24c','#fd8d3c','#fc4e2a','#e31a1c','#bd0026','#800026') #sequential
plot_lat_difference <- function(mdl1, mdl2){
#function to produce a timeseries of plots showing the deviation in the reconstructed temporal latitudes of the spatial data points according to the two models (mdl1 and mdl2)
#be careful with the order of the models you are comparing, otherwise, the file won't be recognized
filename <- paste0("./data/latitude_deviation_2_by_2/", mdl1, '_', mdl2, 'diff.csv')
df <- readRDS(filename)
for(k in seq(from = 4, to = ncol(df), by = 2)){ #we start with the latitude of the -10My point (4th column)
true_time <- (k-2)*5 #for the plot title ( = ((k-2)/2)*10 )
xyz <- df[, c(1,2,k)] #select the corresponding latitude deviation
r <- rasterFromXYZ(xyz,
crs = "+proj=longlat +datum=WGS84")  #write the raster file with the UTM projection coord sys
proj_moll <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0"  #mollweide projection
p <- projectRaster(r, crs = proj_moll)
if(true_time < 100){  #add a zero in front of true_time in the name of the file so that the program used to compile the plot as a GIF could sort them properely
png(paste0("./figures/", mdl1,"_vs_", mdl2, "/", mdl1,"_v.s_", mdl2, '_', 0, true_time, ".png"))
}
else{
png(paste0("./figures/", mdl1,"_vs_", mdl2, "/", mdl1,"_v.s_", mdl2, '_', true_time, ".png"))
}
plot.new()
#
# rect(par("usr")[1], par("usr")[3],
#      par("usr")[2], par("usr")[4],
#      col = "grey92") #set light grey background
# par(new = TRUE)
par(bg = "grey92")
plot(p,
axes = FALSE,
col = pal,
main = paste0("Latitude deviation beteen ", mdl1, " and ", mdl2, " (", true_time ,"Ma)"),
legend.args = list(text = 'Latitude deviation', side = 4, font = 2, line = 2.5, cex = 0.8),
zlim = c(0, 60))  #display the output
plot(worldline_mol,
add = TRUE)  #add background map
dev.off()
}
return()
}
#computing the function for all the models
i = 1
models_copy = models
while(i <= length(models)){
mdl1 <- models[[i]]
for(mdl2 in models_copy){
if(mdl1 != mdl2){
plot_lat_difference(mdl1, mdl2)
}
}
models_copy = models_copy[-1]  #we get rid of the new first element
i = i+1
}
plot_lat_difference <- function(mdl1, mdl2){
#function to produce a timeseries of plots showing the deviation in the reconstructed temporal latitudes of the spatial data points according to the two models (mdl1 and mdl2)
#be careful with the order of the models you are comparing, otherwise, the file won't be recognized
filename <- paste0("./data/latitude_deviation_2_by_2/", mdl1, '_', mdl2, 'diff.csv')
print(filename)
df <- readRDS(filename)
for(k in seq(from = 4, to = ncol(df), by = 2)){ #we start with the latitude of the -10My point (4th column)
true_time <- (k-2)*5 #for the plot title ( = ((k-2)/2)*10 )
xyz <- df[, c(1,2,k)] #select the corresponding latitude deviation
r <- rasterFromXYZ(xyz,
crs = "+proj=longlat +datum=WGS84")  #write the raster file with the UTM projection coord sys
proj_moll <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0"  #mollweide projection
p <- projectRaster(r, crs = proj_moll)
if(true_time < 100){  #add a zero in front of true_time in the name of the file so that the program used to compile the plot as a GIF could sort them properely
png(paste0("./figures/", mdl1,"_vs_", mdl2, "/", mdl1,"_v.s_", mdl2, '_', 0, true_time, ".png"))
}
else{
png(paste0("./figures/", mdl1,"_vs_", mdl2, "/", mdl1,"_v.s_", mdl2, '_', true_time, ".png"))
}
plot.new()
#
# rect(par("usr")[1], par("usr")[3],
#      par("usr")[2], par("usr")[4],
#      col = "grey92") #set light grey background
# par(new = TRUE)
par(bg = "grey92")
plot(p,
axes = FALSE,
col = pal,
main = paste0("Latitude deviation beteen ", mdl1, " and ", mdl2, " (", true_time ,"Ma)"),
legend.args = list(text = 'Latitude deviation', side = 4, font = 2, line = 2.5, cex = 0.8),
zlim = c(0, 60))  #display the output
plot(worldline_mol,
add = TRUE)  #add background map
dev.off()
}
return()
}
#computing the function for all the models
i = 1
models_copy = models
while(i <= length(models)){
mdl1 <- models[[i]]
for(mdl2 in models_copy){
if(mdl1 != mdl2){
plot_lat_difference(mdl1, mdl2)
}
}
models_copy = models_copy[-1]  #we get rid of the new first element
i = i+1
}
## Plot and save latitude deviation 2 by 2 for all the models time series -------------
source("./R/plot_lat_deviation.R")
## Plot and save plateIDs assignement discrepancies -----------------------------------
source("./R/plot_ID_weight.R")
