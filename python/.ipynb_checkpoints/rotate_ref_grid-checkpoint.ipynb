{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663a096b-64bd-4265-a763-dc8396c294c5",
   "metadata": {},
   "source": [
    "### This notebook imports a reference grid, reconstructs it according to a specified plate model and exports the rotated grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc876416-49ee-4427-9c00-4e023936f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygplates as pygp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508d724-d7bf-46b4-a70b-5dc2abc66cdd",
   "metadata": {},
   "source": [
    "#### User input: time range, plate model files and desired output file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975b7019-05d0-481b-b5a3-cb5e872d2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 10    # start time (in Ma) = youngest reconstruction step (e.g. not t=0)\n",
    "stop = 540    # stop time (in Ma) = oldest reconstruction step\n",
    "step = 10     # temporal step size (in Ma)\n",
    "\n",
    "reference_grid = 'reference_grid/reference_grid.csv'              # reference grid file\n",
    "static_polygons = 'plate_models/TC16/TC16_static_polygons.gpml'   # static polygon file\n",
    "rotation_model = 'plate_models/TC16/TC16_rot_model.rot'           # rotation file\n",
    "anchor_plate = 1                                                  # anchor plate ID (sets the effective reference frame)\n",
    "\n",
    "rotated_grid = 'rotated_grids/TC16.csv'                           # output file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea270272-ae51-4be6-96c0-30343cc581e2",
   "metadata": {},
   "source": [
    "#### Import reference grid and build dataframe to append rotated points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a292f715-111e-4141-8b43-ee3589c56cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(reference_grid, usecols=[0,1], header=0).dropna().reset_index(drop=True)        # ignore empty lines\n",
    "df['pygp_pts'] = df.apply(lambda row: pygp.PointOnSphere((row.lat, row.lng)), axis=1)            # convert lat/lons to pygplates point format and append as new column\n",
    "df['plt_id'] = np.nan                     # plate id (to be assigned by partitioning step)\n",
    "df['maxage'] = np.nan                     # maximum age of the reconstructable point (to be assigned by partitioning step)\n",
    "df['pygp_feature'] = np.nan               # bundled pygplates data (point, plate id and valid age)\n",
    "df['plt_id'] = df['plt_id'].astype('Int64')      # this allows this column of NaNs to later be updated with ints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff025de-8c16-48c0-9ec6-2e9f5c874224",
   "metadata": {},
   "source": [
    "#### Assign plate IDs to each reference grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ee1109-cf8d-4f6c-95ee-b93731c95261",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_features = []\n",
    "for i in df['pygp_pts']:                  # bundle all the points together into a gplates feature file to expedite partitioning function call\n",
    "    point_feature = pygp.Feature()\n",
    "    point_feature.set_geometry(i)\n",
    "    point_features.append(point_feature)\n",
    "    \n",
    "partitioned_features = pygp.partition_into_plates(static_polygons, rotation_model, point_features,\n",
    "                                                  properties_to_copy = [pygp.PartitionProperty.reconstruction_plate_id,\n",
    "                                                                        pygp.PartitionProperty.valid_time_period],\n",
    "                                                  sort_partitioning_plates=pygp.SortPartitioningPlates.by_plate_area)\n",
    "partitioned_data = []\n",
    "for i in partitioned_features:            # extract plate ID, maximum age and point location from partitioned features\n",
    "    point = i.get_geometry()\n",
    "    plt_id = i.get_reconstruction_plate_id()\n",
    "    if plt_id == 0: plt_id = np.nan\n",
    "    begin_time, end_time = i.get_valid_time()\n",
    "    partitioned_data.append([point, plt_id, begin_time, i])\n",
    "\n",
    "for i in partitioned_data:                # append these data to our dataframe\n",
    "    df.loc[df['pygp_pts'] == i[0], ['plt_id', 'maxage', 'pygp_feature']] = i[1], i[2], i[3]\n",
    "    \n",
    "    # *** the line above will introduce problems if there are duplicate points (same lat/lon). \n",
    "    # if duplicate points are expected use the two lines below instead (this will be slight slower):\n",
    "    # idx = df[(df.pygp_pts == i[0]) & (pd.isnull(df.pygp_feature))].index[0] \n",
    "    # df.loc[idx,['plt_id', 'maxage', 'pygp_feature']] = i[1], i[2], i[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e0d02-9d95-49e1-8c5c-51daf0660180",
   "metadata": {},
   "source": [
    "#### Reconstruct points through time range and append to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e63fcb-5af2-4152-bb2c-43d5a4d94693",
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in range(start, stop+step, step):\n",
    "    reconstruct = df.loc[(df['plt_id'] != np.nan) & (df['maxage'] >= time)].copy()  # for each timestep select subset of reconstructable points\n",
    "                                        \n",
    "    reconstructed_geometries = []\n",
    "    pygp.reconstruct(reconstruct['pygp_feature'], rotation_model, reconstructed_geometries, time, anchor_plate_id = anchor_plate) # reconstruct points\n",
    "    reconstructed_points = [x.get_reconstructed_geometry().to_lat_lon() for x in reconstructed_geometries]    # extract lat and lon from reconstructed points\n",
    "    reconstructed_lats = [x[0] for x in reconstructed_points]\n",
    "    reconstructed_lons = [x[1] for x in reconstructed_points]\n",
    "    reconstruct[f'lat_{time}'] = reconstructed_lats\n",
    "    reconstruct[f'lng_{time}'] = reconstructed_lons\n",
    "    df = pd.concat([df, reconstruct[f'lng_{time}'], reconstruct[f'lat_{time}']], axis=1, join='outer') # append reconstructed lat & lons back to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540db5c7-2696-478e-afce-9a7bb397b235",
   "metadata": {},
   "source": [
    "#### Tidy dataframe and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3947406-4a81-4352-8a04-b2961893d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['pygp_pts', 'plt_id', 'maxage', 'pygp_feature'])   # drop columns that we don't need\n",
    "df.to_csv(rotated_grid, index=False, na_rep='NA', float_format='%.4f')   # set format of NaNs + precision of floats and save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
